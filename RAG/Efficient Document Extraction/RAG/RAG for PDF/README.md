# ğŸ§  Document-based RAG QA System with LanceDB, HuggingFace & Ollama

This project implements a Retrieval-Augmented Generation (RAG) system that extracts content from Documents, chunks and embeds the data into a vector database (LanceDB), and enables question answering using either HuggingFace or Ollama language models.


## ğŸ”¥ Features

- ğŸ“„ **PDF Parsing**: Extracts rich content (text, tables, images) using `docling`.
- ğŸ–¼ï¸ **Image Summarization**: Auto-generates image descriptions using `LLaVA` (`ollama`).
- ğŸ§© **Intelligent Chunking**: Document segmentation using `markdownsplitter` and `recursivecharactertextsplitter`.
- ğŸ§  **Embeddings**: Sentence-level embeddings via `all-mpnet-base-v2`.
- ğŸ› **Vector Storage**: Stores embeddings efficiently into **LanceDB**.
- ğŸ¤– **Question Answering**:
  - `huggingface_QA.py`: HuggingFace LLaMA for text-based QA.
  - `ollama_QA.py`: Local Ollama models (`mistral:latest`, `llava`) for multimodal QA.

---

- Python 3.10 +
- CUDA-compatible GPU
- `ollama` running locally (`ollama serve`)

 ---


## ğŸŒ Semantic Web Search to LanceDB Pipeline

This project implements a full pipeline for semantic web search using Google, content crawling, markdown formatting, chunking, and vector storage using `SentenceTransformer` and `LanceDB`.


## ğŸ§  Use Cases

- ğŸ” Intelligent Search Indexing
- ğŸ“– LLM-based Document Q&A (RAG)
- ğŸ§‘â€ğŸ’» Research Assistance
- ğŸ“‚ Knowledge Base Creation
- ğŸ¤– Preprocessing for Chatbot Memory

---

## ğŸ“¦ Features


- ğŸ” Google Search
    â‡©
- ğŸŒ URL Metadata & Validation
    â‡©
- ğŸ•¸ï¸ Async Crawling with Crawl4AI
    â‡©
- ğŸ“ Markdown Normalization
    â‡©
- âœ‚ï¸ Smart Chunking (MarkdownHeader + RecursiveSplitter)
    â‡©
- ğŸ§  SentenceTransformers Embedding using `all-mpnet-base-v2`
    â‡©
- ğŸ—ƒï¸ LanceDB Vector Storage

---

## ğŸ› ï¸ Requirements

Install the following dependencies:


```bash
pip install -r requirements.txt